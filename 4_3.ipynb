{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4.3 – Variational Autoencoder (VAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3.1 Conceptual introduction to Variational Autoencoders (VAEs)\n",
    "\n",
    "A Variational Autoencoder (VAE) is a generative model that learns a probabilistic latent representation of data.\n",
    "It consists of:\n",
    "- an encoder $q_\\phi(\\mathbf{z}\\mid\\mathbf{x})$ that maps data $\\mathbf{x}$ to a distribution over latent variables $\\mathbf{z}$,\n",
    "- a decoder $p_\\theta(\\mathbf{x}\\mid\\mathbf{z})$ that maps latent variables back to a distribution over data.\n",
    "\n",
    "### Notation and assumptions\n",
    "- Prior on latent variables: $p(\\mathbf{z}) = \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$.\n",
    "- Variational posterior (encoder): $q_\\phi(\\mathbf{z}\\mid\\mathbf{x}) = \\mathcal{N}\\!\\big(\\boldsymbol\\mu_\\phi(\\mathbf{x}), \\mathrm{diag}(\\boldsymbol\\sigma^2_\\phi(\\mathbf{x}))\\big)$.\n",
    "  In practice we predict $\\boldsymbol\\mu$ and $\\log\\boldsymbol\\sigma^2$ (aka `logvar`) for numerical stability.\n",
    "- Likelihood (decoder): $p_\\theta(\\mathbf{x}\\mid\\mathbf{z})$.\n",
    "  - If we use mean squared error (MSE) as reconstruction loss, this corresponds to a Gaussian likelihood with fixed variance: $p_\\theta(\\mathbf{x}\\mid\\mathbf{z}) = \\mathcal{N}(\\hat{\\mathbf{x}}_\\theta(\\mathbf{z}), \\beta \\mathbf{I})$ (for some $\\beta>0$).\n",
    "  - If we use binary cross-entropy (BCE) on $[0,1]$ images, this corresponds to a Bernoulli likelihood with mean $\\hat{\\mathbf{x}}_\\theta(\\mathbf{z})$.\n",
    "\n",
    "### Objective: ELBO\n",
    "Maximizing the log marginal likelihood $\\log p_\\theta(\\mathbf{x})$ directly is intractable,\n",
    "so we maximize the Evidence Lower BOund (ELBO):\n",
    "$$\n",
    "\\mathcal{L}_{\\text{ELBO}}(\\theta,\\phi;\\mathbf{x})\n",
    "= \\mathbb{E}_{q_\\phi(\\mathbf{z}\\mid\\mathbf{x})}\\big[\\log p_\\theta(\\mathbf{x}\\mid\\mathbf{z})\\big]\n",
    "- \\mathrm{KL}\\!\\big(q_\\phi(\\mathbf{z}\\mid\\mathbf{x}) \\,\\|\\, p(\\mathbf{z})\\big).\n",
    "$$\n",
    "Training conventionally minimizes the negative ELBO:\n",
    "$$\n",
    "\\mathcal{L}_{\\text{VAE}}(\\mathbf{x})\n",
    "= -\\,\\mathbb{E}_{q_\\phi(\\mathbf{z}\\mid\\mathbf{x})}\\big[\\log p_\\theta(\\mathbf{x}\\mid\\mathbf{z})\\big]\n",
    "+ \\mathrm{KL}\\!\\big(q_\\phi(\\mathbf{z}\\mid\\mathbf{x}) \\,\\|\\, p(\\mathbf{z})\\big).\n",
    "$$\n",
    "\n",
    "For Gaussian decoder with fixed variance $\\beta\\mathbf{I}$, the first term reduces (up to a constant scale) to the per-pixel MSE between $\\mathbf{x}$ and $\\hat{\\mathbf{x}}=\\hat{\\mathbf{x}}_\\theta(\\mathbf{z})$:\n",
    "$$\n",
    "-\\,\\mathbb{E}_{q}\\big[\\log p_\\theta(\\mathbf{x}\\mid\\mathbf{z})\\big]\n",
    "\\propto \\frac{1}{2\\beta}\\,\\|\\mathbf{x}-\\hat{\\mathbf{x}}\\|_2^2.\n",
    "$$\n",
    "In practice we implement it as an MSE over pixels/channels, reduced to a scalar per batch.\n",
    "\n",
    "### Closed-form KL for diagonal Gaussians\n",
    "With $q_\\phi(\\mathbf{z}\\mid\\mathbf{x})=\\mathcal{N}(\\boldsymbol\\mu, \\mathrm{diag}(\\boldsymbol\\sigma^2))$ and $p(\\mathbf{z})=\\mathcal{N}(\\mathbf{0},\\mathbf{I})$:\n",
    "$$\n",
    "\\mathrm{KL}\\!\\big(q \\,\\|\\, p\\big)\n",
    "= \\frac{1}{2}\\sum_{i=1}^d \\big(\\mu_i^2 + \\sigma_i^2 - \\log \\sigma_i^2 - 1\\big).\n",
    "$$\n",
    "Using `logvar = \\log \\sigma^2`, one computes $\\sigma^2 = \\exp(\\text{logvar})$ and uses the same formula.\n",
    "\n",
    "### Reparameterization trick\n",
    "To backpropagate through sampling from $q_\\phi(\\mathbf{z}\\mid\\mathbf{x})$, we write\n",
    "$$\n",
    "\\mathbf{z} = \\boldsymbol\\mu + \\boldsymbol\\sigma \\odot \\boldsymbol\\epsilon,\n",
    "\\quad \\boldsymbol\\epsilon \\sim \\mathcal{N}(\\mathbf{0},\\mathbf{I}),\n",
    "\\quad \\boldsymbol\\sigma = \\exp\\!\\big(\\tfrac{1}{2}\\,\\text{logvar}\\big).\n",
    "$$\n",
    "This makes sampling a deterministic function of $(\\boldsymbol\\mu,\\text{logvar},\\boldsymbol\\epsilon)$, enabling gradient flow.\n",
    "\n",
    "### Practical implementation notes (for the next steps)\n",
    "- Encoder outputs: `mu`, `logvar`; use a `Sampling` layer to produce `z`.\n",
    "- Decoder outputs: reconstruction $\\hat{\\mathbf{x}}$ in $[0,1]$ via a final `sigmoid` when inputs are normalized to $[0,1]$.\n",
    "- Loss per batch:\n",
    "  - Reconstruction: sum over pixels/channels per sample, then mean over batch (consistent scalar).\n",
    "  - KL: sum over latent dims per sample, then mean over batch.\n",
    "  - Total: `loss = recon_loss + kl_loss` (matching the exercise statement).\n",
    "- Architectures for 28×28 images:\n",
    "  - Encoder: Conv2D blocks with strides 2 to reduce to 7×7, then Dense to latent parameters.\n",
    "  - Decoder: Dense to 7×7×C, then Conv2DTranspose with strides 2 to upsample back to 28×28.\n",
    "- 2D latent ($d=2$) enables direct scatter plots and grid sampling visualizations.\n",
    "- Uncertainty maps: multiple stochastic decodes for the same input yield per-pixel variance heatmaps.\n",
    "\n",
    "### What to remember\n",
    "- VAE optimizes a trade-off: accurate reconstructions vs. latent regularity (KL toward a standard normal).\n",
    "- Using MSE corresponds to a Gaussian decoder; BCE corresponds to a Bernoulli decoder.\n",
    "- Reparameterization trick is the key to make stochastic sampling differentiable.\n",
    "- For diagonal Gaussians, the KL term is analytic and cheap to compute.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3.2 Fashion-MNIST: load, normalize, and visualize one sample per class\n",
    "\n",
    "What we will do:\n",
    "- Download Fashion-MNIST (60k train, 10k test), grayscale 28×28 images.\n",
    "- Normalize to [0,1] and add a channel dimension -> shape (N, 28, 28, 1).\n",
    "- Plot one randomly selected sample for each of the 10 classes.\n",
    "- Optionally restrict training to the first 10,000 samples for speed (as allowed by the exercise).\n",
    "\n",
    "Why:\n",
    "- Normalization stabilizes optimization for subsequent model training.\n",
    "- The channel dimension is required by Conv2D layers.\n",
    "- Per-class samples help us visually inspect the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-macos\n",
      "  Downloading tensorflow_macos-2.16.2-cp310-cp310-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-metal\n",
      "  Downloading tensorflow_metal-1.2.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (1.3 kB)\n",
      "Collecting tensorflow==2.16.2 (from tensorflow-macos)\n",
      "  Downloading tensorflow-2.16.2-cp310-cp310-macosx_12_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading h5py-3.15.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading ml_dtypes-0.3.2-cp310-cp310-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /Users/jacopocaldana/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from tensorflow==2.16.2->tensorflow-macos) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading protobuf-4.25.8-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/jacopocaldana/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from tensorflow==2.16.2->tensorflow-macos) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/jacopocaldana/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from tensorflow==2.16.2->tensorflow-macos) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/jacopocaldana/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/jacopocaldana/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from tensorflow==2.16.2->tensorflow-macos) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading wrapt-2.0.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (8.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading grpcio-1.76.0-cp310-cp310-macosx_11_0_universal2.whl.metadata (3.7 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Collecting numpy<2.0.0,>=1.23.5 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jacopocaldana/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jacopocaldana/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jacopocaldana/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jacopocaldana/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (2024.12.14)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting wheel~=0.35 (from tensorflow-metal)\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading optree-0.17.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/jacopocaldana/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/jacopocaldana/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow_macos-2.16.2-cp310-cp310-macosx_12_0_arm64.whl (2.1 kB)\n",
      "Downloading tensorflow-2.16.2-cp310-cp310-macosx_12_0_arm64.whl (227.0 MB)\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/227.0 MB\u001b[0m \u001b[31m173.0 kB/s\u001b[0m eta \u001b[36m0:16:27\u001b[0m"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-macos tensorflow-metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Imports and basic setup for this section\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility (subject to GPU/cuDNN determinism limits)\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Plot style\n",
    "sns.set(context=\"notebook\", style=\"whitegrid\", palette=\"deep\")\n",
    "plt.rcParams[\"figure.figsize\"] = (5.5, 5.0)\n",
    "plt.rcParams[\"axes.titlesize\"] = 12\n",
    "plt.rcParams[\"axes.labelsize\"] = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Fashion-MNIST\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Normalize to [0,1] and add channel dimension\n",
    "x_train = (x_train.astype(\"float32\") / 255.0)[..., None]  # (N, 28, 28, 1)\n",
    "x_test  = (x_test.astype(\"float32\")  / 255.0)[..., None]\n",
    "\n",
    "class_names = [\n",
    "    \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "    \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n",
    "]\n",
    "\n",
    "print(\"Train:\", x_train.shape, y_train.shape)\n",
    "print(\"Test: \", x_test.shape, y_test.shape)\n",
    "\n",
    "# Optionally limit to first 10k training samples for speed\n",
    "USE_FIRST_10K = True  # set to False for the full 60k\n",
    "if USE_FIRST_10K:\n",
    "    x_train = x_train[:10000]\n",
    "    y_train = y_train[:10000]\n",
    "    print(\"Using subset of training data:\", x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one random sample per class from the (possibly reduced) training set\n",
    "rng = np.random.default_rng(SEED)\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 4.2))\n",
    "picked_indices = []\n",
    "\n",
    "for c in range(10):\n",
    "    indices = np.where(y_train == c)[0]\n",
    "    idx = rng.choice(indices)\n",
    "    picked_indices.append(idx)\n",
    "\n",
    "for ax, idx, c in zip(axes.ravel(), picked_indices, range(10)):\n",
    "    ax.imshow(x_train[idx].squeeze(), cmap=\"gray\", vmin=0, vmax=1)\n",
    "    ax.set_title(class_names[c])\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "fig.suptitle(\"Fashion-MNIST: one random training sample per class\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
