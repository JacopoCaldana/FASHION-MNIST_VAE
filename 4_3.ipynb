{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4.3 – Variational Autoencoder (VAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3.1 Conceptual introduction to Variational Autoencoders (VAEs)\n",
    "\n",
    "A Variational Autoencoder (VAE) is a generative model that learns a probabilistic latent representation of data.\n",
    "It consists of:\n",
    "- an encoder $q_\\phi(\\mathbf{z}\\mid\\mathbf{x})$ that maps data $\\mathbf{x}$ to a distribution over latent variables $\\mathbf{z}$,\n",
    "- a decoder $p_\\theta(\\mathbf{x}\\mid\\mathbf{z})$ that maps latent variables back to a distribution over data.\n",
    "\n",
    "### Notation and assumptions\n",
    "- Prior on latent variables: $p(\\mathbf{z}) = \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$.\n",
    "- Variational posterior (encoder): $q_\\phi(\\mathbf{z}\\mid\\mathbf{x}) = \\mathcal{N}\\!\\big(\\boldsymbol\\mu_\\phi(\\mathbf{x}), \\mathrm{diag}(\\boldsymbol\\sigma^2_\\phi(\\mathbf{x}))\\big)$.\n",
    "  In practice we predict $\\boldsymbol\\mu$ and $\\log\\boldsymbol\\sigma^2$ (aka `logvar`) for numerical stability.\n",
    "- Likelihood (decoder): $p_\\theta(\\mathbf{x}\\mid\\mathbf{z})$.\n",
    "  - If we use mean squared error (MSE) as reconstruction loss, this corresponds to a Gaussian likelihood with fixed variance: $p_\\theta(\\mathbf{x}\\mid\\mathbf{z}) = \\mathcal{N}(\\hat{\\mathbf{x}}_\\theta(\\mathbf{z}), \\beta \\mathbf{I})$ (for some $\\beta>0$).\n",
    "  - If we use binary cross-entropy (BCE) on $[0,1]$ images, this corresponds to a Bernoulli likelihood with mean $\\hat{\\mathbf{x}}_\\theta(\\mathbf{z})$.\n",
    "\n",
    "### Objective: ELBO\n",
    "Maximizing the log marginal likelihood $\\log p_\\theta(\\mathbf{x})$ directly is intractable,\n",
    "so we maximize the Evidence Lower BOund (ELBO):\n",
    "$$\n",
    "\\mathcal{L}_{\\text{ELBO}}(\\theta,\\phi;\\mathbf{x})\n",
    "= \\mathbb{E}_{q_\\phi(\\mathbf{z}\\mid\\mathbf{x})}\\big[\\log p_\\theta(\\mathbf{x}\\mid\\mathbf{z})\\big]\n",
    "- \\mathrm{KL}\\!\\big(q_\\phi(\\mathbf{z}\\mid\\mathbf{x}) \\,\\|\\, p(\\mathbf{z})\\big).\n",
    "$$\n",
    "Training conventionally minimizes the negative ELBO:\n",
    "$$\n",
    "\\mathcal{L}_{\\text{VAE}}(\\mathbf{x})\n",
    "= -\\,\\mathbb{E}_{q_\\phi(\\mathbf{z}\\mid\\mathbf{x})}\\big[\\log p_\\theta(\\mathbf{x}\\mid\\mathbf{z})\\big]\n",
    "+ \\mathrm{KL}\\!\\big(q_\\phi(\\mathbf{z}\\mid\\mathbf{x}) \\,\\|\\, p(\\mathbf{z})\\big).\n",
    "$$\n",
    "\n",
    "For Gaussian decoder with fixed variance $\\beta\\mathbf{I}$, the first term reduces (up to a constant scale) to the per-pixel MSE between $\\mathbf{x}$ and $\\hat{\\mathbf{x}}=\\hat{\\mathbf{x}}_\\theta(\\mathbf{z})$:\n",
    "$$\n",
    "-\\,\\mathbb{E}_{q}\\big[\\log p_\\theta(\\mathbf{x}\\mid\\mathbf{z})\\big]\n",
    "\\propto \\frac{1}{2\\beta}\\,\\|\\mathbf{x}-\\hat{\\mathbf{x}}\\|_2^2.\n",
    "$$\n",
    "In practice we implement it as an MSE over pixels/channels, reduced to a scalar per batch.\n",
    "\n",
    "### Closed-form KL for diagonal Gaussians\n",
    "With $q_\\phi(\\mathbf{z}\\mid\\mathbf{x})=\\mathcal{N}(\\boldsymbol\\mu, \\mathrm{diag}(\\boldsymbol\\sigma^2))$ and $p(\\mathbf{z})=\\mathcal{N}(\\mathbf{0},\\mathbf{I})$:\n",
    "$$\n",
    "\\mathrm{KL}\\!\\big(q \\,\\|\\, p\\big)\n",
    "= \\frac{1}{2}\\sum_{i=1}^d \\big(\\mu_i^2 + \\sigma_i^2 - \\log \\sigma_i^2 - 1\\big).\n",
    "$$\n",
    "Using `logvar = \\log \\sigma^2`, one computes $\\sigma^2 = \\exp(\\text{logvar})$ and uses the same formula.\n",
    "\n",
    "### Reparameterization trick\n",
    "To backpropagate through sampling from $q_\\phi(\\mathbf{z}\\mid\\mathbf{x})$, we write\n",
    "$$\n",
    "\\mathbf{z} = \\boldsymbol\\mu + \\boldsymbol\\sigma \\odot \\boldsymbol\\epsilon,\n",
    "\\quad \\boldsymbol\\epsilon \\sim \\mathcal{N}(\\mathbf{0},\\mathbf{I}),\n",
    "\\quad \\boldsymbol\\sigma = \\exp\\!\\big(\\tfrac{1}{2}\\,\\text{logvar}\\big).\n",
    "$$\n",
    "This makes sampling a deterministic function of $(\\boldsymbol\\mu,\\text{logvar},\\boldsymbol\\epsilon)$, enabling gradient flow.\n",
    "\n",
    "### Practical implementation notes (for the next steps)\n",
    "- Encoder outputs: `mu`, `logvar`; use a `Sampling` layer to produce `z`.\n",
    "- Decoder outputs: reconstruction $\\hat{\\mathbf{x}}$ in $[0,1]$ via a final `sigmoid` when inputs are normalized to $[0,1]$.\n",
    "- Loss per batch:\n",
    "  - Reconstruction: sum over pixels/channels per sample, then mean over batch (consistent scalar).\n",
    "  - KL: sum over latent dims per sample, then mean over batch.\n",
    "  - Total: `loss = recon_loss + kl_loss` (matching the exercise statement).\n",
    "- Architectures for 28×28 images:\n",
    "  - Encoder: Conv2D blocks with strides 2 to reduce to 14×14, then Dense to latent parameters.\n",
    "  - Decoder: Dense to 14×14×C, then Conv2DTranspose with strides 2 to upsample back to 28×28.\n",
    "- 2D latent ($d=2$) enables direct scatter plots and grid sampling visualizations.\n",
    "- Uncertainty maps: multiple stochastic decodes for the same input yield per-pixel variance heatmaps.\n",
    "\n",
    "### What to remember\n",
    "- VAE optimizes a trade-off: accurate reconstructions vs. latent regularity (KL toward a standard normal).\n",
    "- Using MSE corresponds to a Gaussian decoder; BCE corresponds to a Bernoulli decoder.\n",
    "- Reparameterization trick is the key to make stochastic sampling differentiable.\n",
    "- For diagonal Gaussians, the KL term is analytic and cheap to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3.2 Fashion-MNIST: load, normalize, and visualize one sample per class\n",
    "\n",
    "What we will do:\n",
    "- Download Fashion-MNIST (60k train, 10k test), grayscale 28×28 images.\n",
    "- Normalize to [0,1] and add a channel dimension -> shape (N, 28, 28, 1).\n",
    "- Plot one randomly selected sample for each of the 10 classes.\n",
    "- Optionally restrict training to the first 10,000 samples for speed (as allowed by the exercise).\n",
    "\n",
    "Why:\n",
    "- Normalization stabilizes optimization for subsequent model training.\n",
    "- The channel dimension is required by Conv2D layers.\n",
    "- Per-class samples help us visually inspect the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and basic setup for this section\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility (subject to GPU/cuDNN determinism limits)\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Fashion-MNIST\n",
    "(x_train_full, y_train_full), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Normalize to [0,1] and add channel dimension\n",
    "x_train_full = x_train_full.astype('float32') / 255.0\n",
    "x_train_full = x_train_full[..., np.newaxis]  # (60000, 28, 28, 1)\n",
    "\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "x_test = x_test[..., np.newaxis]  # (10000, 28, 28, 1)\n",
    "\n",
    "# For faster experimentation, optionally use a subset of training data\n",
    "# (The exercise allows up to 10k samples for speed)\n",
    "USE_SUBSET = False  # Set to True to use only first 10k samples\n",
    "if USE_SUBSET:\n",
    "    x_train = x_train_full[:10000]\n",
    "    y_train = y_train_full[:10000]\n",
    "else:\n",
    "    x_train = x_train_full\n",
    "    y_train = y_train_full\n",
    "\n",
    "print(f\"Training data shape: {x_train.shape}\")\n",
    "print(f\"Test data shape: {x_test.shape}\")\n",
    "print(f\"Value range: [{x_train.min():.2f}, {x_train.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one random sample per class from the (possibly reduced) training set\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for c in range(10):\n",
    "    idx_c = np.where(y_train == c)[0]\n",
    "    if len(idx_c) > 0:\n",
    "        sample_idx = np.random.choice(idx_c)\n",
    "        axes[c].imshow(x_train[sample_idx].squeeze(), cmap='gray')\n",
    "        axes[c].set_title(f\"{c}: {class_names[c]}\")\n",
    "        axes[c].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3.3 Implement VAE loss: MSE reconstruction + KL divergence\n",
    "\n",
    "We implement the three loss functions as specified in the assignment:\n",
    "\n",
    "1. **Reconstruction loss (MSE)**: Sum of squared errors per pixel for each sample, then mean over batch.\n",
    "   $$L_{\\text{recon}}(\\mathbf{x}, \\hat{\\mathbf{x}}) = \\frac{1}{B}\\sum_{b=1}^B \\sum_{\\text{pixels}} (x_b - \\hat{x}_b)^2$$\n",
    "\n",
    "2. **KL divergence**: Analytic formula for diagonal Gaussian vs standard normal, per sample, then mean over batch.\n",
    "   $$L_{\\text{KL}}(\\boldsymbol\\mu, \\log\\boldsymbol\\sigma^2) = \\frac{1}{B}\\sum_{b=1}^B \\frac{1}{2}\\sum_{i=1}^d \\big(\\mu_{bi}^2 + \\sigma_{bi}^2 - \\log\\sigma_{bi}^2 - 1\\big)$$\n",
    "\n",
    "3. **Total VAE loss**: Sum of reconstruction and KL losses (with β=1).\n",
    "   $$L_{\\text{VAE}} = L_{\\text{recon}} + L_{\\text{KL}}$$\n",
    "\n",
    "All functions return scalars as required by the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import ops\n",
    "\n",
    "def reconstruction_loss_mse(x, x_hat):\n",
    "    \"\"\"\n",
    "    MSE reconstruction loss for VAE.\n",
    "    \n",
    "    Computes the sum of squared errors per sample (over all pixels/channels),\n",
    "    then averages over the batch.\n",
    "    \n",
    "    Args:\n",
    "        x: True images, shape (batch, height, width, channels)\n",
    "        x_hat: Reconstructed images, shape (batch, height, width, channels)\n",
    "    \n",
    "    Returns:\n",
    "        Scalar tensor: mean reconstruction loss over batch\n",
    "    \"\"\"\n",
    "    # Sum squared error per sample (over spatial and channel dims)\n",
    "    per_sample_loss = ops.sum(ops.square(x - x_hat), axis=[1, 2, 3])\n",
    "    # Mean over batch\n",
    "    return ops.mean(per_sample_loss)\n",
    "\n",
    "\n",
    "def kl_loss_diag_gaussian(mu, log_var):\n",
    "    \"\"\"\n",
    "    Analytic KL divergence for diagonal Gaussian vs standard normal prior.\n",
    "    \n",
    "    Formula: KL(q(z|x) || p(z)) = 0.5 * sum_i (mu_i^2 + sigma_i^2 - log(sigma_i^2) - 1)\n",
    "    where sigma_i^2 = exp(log_var_i).\n",
    "    \n",
    "    We sum over latent dimensions per sample, then average over batch.\n",
    "    \n",
    "    Args:\n",
    "        mu: Mean of latent distribution, shape (batch, latent_dim)\n",
    "        log_var: Log variance of latent distribution, shape (batch, latent_dim)\n",
    "    \n",
    "    Returns:\n",
    "        Scalar tensor: mean KL divergence over batch\n",
    "    \"\"\"\n",
    "    # KL per sample (sum over latent dimensions)\n",
    "    per_sample_kl = 0.5 * ops.sum(\n",
    "        ops.square(mu) + ops.exp(log_var) - log_var - 1.0,\n",
    "        axis=1\n",
    "    )\n",
    "    # Mean over batch\n",
    "    return ops.mean(per_sample_kl)\n",
    "\n",
    "\n",
    "def vae_total_loss(x, x_hat, mu, log_var):\n",
    "    \"\"\"\n",
    "    Total VAE loss: reconstruction loss + KL divergence.\n",
    "    \n",
    "    Args:\n",
    "        x: True images, shape (batch, height, width, channels)\n",
    "        x_hat: Reconstructed images, shape (batch, height, width, channels)\n",
    "        mu: Mean of latent distribution, shape (batch, latent_dim)\n",
    "        log_var: Log variance of latent distribution, shape (batch, latent_dim)\n",
    "    \n",
    "    Returns:\n",
    "        Scalar tensor: total loss (recon + KL)\n",
    "    \"\"\"\n",
    "    recon_loss = reconstruction_loss_mse(x, x_hat)\n",
    "    kl = kl_loss_diag_gaussian(mu, log_var)\n",
    "    return recon_loss + kl\n",
    "\n",
    "\n",
    "print(\"Loss functions defined successfully.\")\n",
    "print(\"- reconstruction_loss_mse(x, x_hat): Sum SSE per sample → mean over batch\")\n",
    "print(\"- kl_loss_diag_gaussian(mu, log_var): Analytic KL per sample → mean over batch\")\n",
    "print(\"- vae_total_loss(x, x_hat, mu, log_var): recon + KL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3.4 Stable VAE implementation with functional API and KL warmup\n",
    "\n",
    "This section provides a single, clean VAE implementation using:\n",
    "- **Functional API** with `add_loss` and `add_metric` to avoid tensor closure issues\n",
    "- **KL warmup**: β increases linearly from 0→1 over WARMUP_EPOCHS (default 40)\n",
    "- **Proper callbacks**: WarmupCallback, ReduceLROnPlateau, EarlyStopping\n",
    "- **Visible metrics**: recon_loss, kl_loss, kl_scaled (β×KL), kl_beta (current β)\n",
    "\n",
    "### Architecture:\n",
    "**Encoder**:\n",
    "- Conv2D(128, 5) → Conv2D(64, 3, stride=2) → Conv2D(64, 3) → Conv2D(64, 3)\n",
    "- Flatten → Dense(32) → z_mean, z_logvar\n",
    "- Reparameterization: z = μ + σ ⊙ ε\n",
    "\n",
    "**Decoder**:\n",
    "- Dense(14×14×64) → Reshape(14,14,64)\n",
    "- Conv2DTranspose(64, 3) → Conv2DTranspose(64, 3) → Conv2DTranspose(64, 3, stride=2)\n",
    "- Conv2DTranspose(128, 5) → Conv2DTranspose(1, 5, sigmoid)\n",
    "\n",
    "### Note on duplicate models:\n",
    "Previous versions (Model2, Model3, etc.) have been consolidated into this single stable implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, callbacks, ops\n",
    "import tensorflow as tf\n",
    "\n",
    "# ============================================================================\n",
    "# Sampling Layer (Reparameterization Trick)\n",
    "# ============================================================================\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Reparameterization trick: z = mu + sigma * epsilon.\"\"\"\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        import keras\n",
    "        mu, log_var = inputs\n",
    "        # Sample epsilon from standard normal, shape matches mu\n",
    "        batch_size = ops.shape(mu)[0]\n",
    "        latent_dim = ops.shape(mu)[1]\n",
    "        epsilon = keras.random.normal(shape=(batch_size, latent_dim))\n",
    "        # z = mu + exp(0.5 * log_var) * epsilon\n",
    "        return mu + ops.exp(0.5 * log_var) * epsilon\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# KL Warmup Callback\n",
    "# ============================================================================\n",
    "\n",
    "class KLWarmupCallback(callbacks.Callback):\n",
    "    \"\"\"Linearly increases beta from 0 to 1 over warmup_epochs.\"\"\"\n",
    "    \n",
    "    def __init__(self, beta_var, warmup_epochs):\n",
    "        super().__init__()\n",
    "        self.beta_var = beta_var\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        # Linear warmup: beta goes from 0 to 1 over warmup_epochs\n",
    "        if epoch < self.warmup_epochs:\n",
    "            new_beta = epoch / self.warmup_epochs\n",
    "        else:\n",
    "            new_beta = 1.0\n",
    "        self.beta_var.assign(new_beta)\n",
    "        print(f\"\\nEpoch {epoch + 1}: beta = {new_beta:.4f}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# VAE Model with Custom train_step\n",
    "# ============================================================================\n",
    "\n",
    "class VAE(models.Model):\n",
    "    \"\"\"VAE with custom train_step for proper loss and metric tracking.\"\"\"\n",
    "    \n",
    "    def __init__(self, encoder, decoder, beta, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.beta = beta\n",
    "        \n",
    "        # Metrics\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name='loss')\n",
    "        self.recon_loss_tracker = keras.metrics.Mean(name='recon_loss')\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name='kl_loss')\n",
    "        self.kl_scaled_tracker = keras.metrics.Mean(name='kl_scaled')\n",
    "        self.kl_beta_tracker = keras.metrics.Mean(name='kl_beta')\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.recon_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            self.kl_scaled_tracker,\n",
    "            self.kl_beta_tracker\n",
    "        ]\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        x, _ = data if isinstance(data, tuple) else (data, data)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass\n",
    "            z_mean, z_log_var, z = self.encoder(x, training=True)\n",
    "            x_recon = self.decoder(z, training=True)\n",
    "            \n",
    "            # Reconstruction loss: sum over pixels per sample, mean over batch\n",
    "            recon_loss = ops.mean(\n",
    "                ops.sum(ops.square(x - x_recon), axis=[1, 2, 3])\n",
    "            )\n",
    "            \n",
    "            # KL loss: sum over latent dims per sample, mean over batch\n",
    "            kl_loss = ops.mean(\n",
    "                0.5 * ops.sum(\n",
    "                    ops.square(z_mean) + ops.exp(z_log_var) - z_log_var - 1.0,\n",
    "                    axis=1\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Total loss with beta warmup\n",
    "            kl_scaled = self.beta * kl_loss\n",
    "            total_loss = recon_loss + kl_scaled\n",
    "        \n",
    "        # Backward pass\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        \n",
    "        # Update metrics\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.recon_loss_tracker.update_state(recon_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        self.kl_scaled_tracker.update_state(kl_scaled)\n",
    "        self.kl_beta_tracker.update_state(self.beta)\n",
    "        \n",
    "        return {\n",
    "            'loss': self.total_loss_tracker.result(),\n",
    "            'recon_loss': self.recon_loss_tracker.result(),\n",
    "            'kl_loss': self.kl_loss_tracker.result(),\n",
    "            'kl_scaled': self.kl_scaled_tracker.result(),\n",
    "            'kl_beta': self.kl_beta_tracker.result()\n",
    "        }\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        x, _ = data if isinstance(data, tuple) else (data, data)\n",
    "        \n",
    "        # Forward pass\n",
    "        z_mean, z_log_var, z = self.encoder(x, training=False)\n",
    "        x_recon = self.decoder(z, training=False)\n",
    "        \n",
    "        # Losses\n",
    "        recon_loss = ops.mean(\n",
    "            ops.sum(ops.square(x - x_recon), axis=[1, 2, 3])\n",
    "        )\n",
    "        \n",
    "        kl_loss = ops.mean(\n",
    "            0.5 * ops.sum(\n",
    "                ops.square(z_mean) + ops.exp(z_log_var) - z_log_var - 1.0,\n",
    "                axis=1\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        kl_scaled = self.beta * kl_loss\n",
    "        total_loss = recon_loss + kl_scaled\n",
    "        \n",
    "        # Update metrics\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.recon_loss_tracker.update_state(recon_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        self.kl_scaled_tracker.update_state(kl_scaled)\n",
    "        self.kl_beta_tracker.update_state(self.beta)\n",
    "        \n",
    "        return {\n",
    "            'loss': self.total_loss_tracker.result(),\n",
    "            'recon_loss': self.recon_loss_tracker.result(),\n",
    "            'kl_loss': self.kl_loss_tracker.result(),\n",
    "            'kl_scaled': self.kl_scaled_tracker.result(),\n",
    "            'kl_beta': self.kl_beta_tracker.result()\n",
    "        }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Build VAE Function\n",
    "# ============================================================================\n",
    "\n",
    "def build_vae(latent_dim=2, warmup_epochs=40):\n",
    "    \"\"\"\n",
    "    Build a VAE using custom Model with train_step and test_step.\n",
    "    \n",
    "    Args:\n",
    "        latent_dim: Dimension of latent space\n",
    "        warmup_epochs: Number of epochs for KL warmup\n",
    "    \n",
    "    Returns:\n",
    "        vae: The complete VAE model\n",
    "        encoder: The encoder model (for inference)\n",
    "        decoder: The decoder model (for generation)\n",
    "        beta: The beta variable (for warmup callback)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Beta variable for KL warmup (trainable=False, used only in loss)\n",
    "    beta = tf.Variable(0.0, trainable=False, dtype=tf.float32, name='kl_beta')\n",
    "    \n",
    "    # ========== ENCODER ==========\n",
    "    encoder_input = layers.Input(shape=(28, 28, 1), name='encoder_input')\n",
    "    \n",
    "    x = layers.Conv2D(128, 5, padding='same', activation='relu', name='enc_conv1')(encoder_input)\n",
    "    x = layers.Conv2D(64, 3, strides=2, padding='same', activation='relu', name='enc_conv2')(x)  # 14x14\n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu', name='enc_conv3')(x)\n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu', name='enc_conv4')(x)\n",
    "    x = layers.Flatten(name='enc_flatten')(x)\n",
    "    x = layers.Dense(32, activation='relu', name='enc_dense')(x)\n",
    "    \n",
    "    z_mean = layers.Dense(latent_dim, name='z_mean')(x)\n",
    "    z_log_var = layers.Dense(latent_dim, name='z_log_var')(x)\n",
    "    z = Sampling(name='z_sampling')([z_mean, z_log_var])\n",
    "    \n",
    "    # Encoder model: input -> [z_mean, z_log_var, z]\n",
    "    encoder = models.Model(encoder_input, [z_mean, z_log_var, z], name='encoder')\n",
    "    \n",
    "    # ========== DECODER ==========\n",
    "    decoder_input = layers.Input(shape=(latent_dim,), name='decoder_input')\n",
    "    \n",
    "    x = layers.Dense(14 * 14 * 64, activation='relu', name='dec_dense')(decoder_input)\n",
    "    x = layers.Reshape((14, 14, 64), name='dec_reshape')(x)\n",
    "    x = layers.Conv2DTranspose(64, 3, padding='same', activation='relu', name='dec_conv1')(x)\n",
    "    x = layers.Conv2DTranspose(64, 3, padding='same', activation='relu', name='dec_conv2')(x)\n",
    "    x = layers.Conv2DTranspose(64, 3, strides=2, padding='same', activation='relu', name='dec_conv3')(x)  # 28x28\n",
    "    x = layers.Conv2DTranspose(128, 5, padding='same', activation='relu', name='dec_conv4')(x)\n",
    "    decoder_output = layers.Conv2DTranspose(1, 5, padding='same', activation='sigmoid', name='dec_output')(x)\n",
    "    \n",
    "    # Decoder model: latent -> reconstruction\n",
    "    decoder = models.Model(decoder_input, decoder_output, name='decoder')\n",
    "    \n",
    "    # ========== VAE ==========\n",
    "    vae = VAE(encoder, decoder, beta, name='vae')\n",
    "    \n",
    "    return vae, encoder, decoder, beta\n",
    "\n",
    "\n",
    "print(\"VAE builder function defined successfully.\")\n",
    "print(\"- Uses custom Model with train_step/test_step\")\n",
    "print(\"- Includes KL warmup via beta variable\")\n",
    "print(\"- Returns: vae, encoder, decoder, beta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Build and Train VAE\n",
    "# ============================================================================\n",
    "\n",
    "# Hyperparameters\n",
    "LATENT_DIM = 2\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-4\n",
    "WARMUP_EPOCHS = 40\n",
    "\n",
    "# Build model\n",
    "vae, encoder, decoder, beta = build_vae(latent_dim=LATENT_DIM, warmup_epochs=WARMUP_EPOCHS)\n",
    "\n",
    "# Compile (no loss needed, already added via add_loss)\n",
    "vae.compile(optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE))\n",
    "\n",
    "# Callbacks\n",
    "callback_list = [\n",
    "    # KL warmup\n",
    "    KLWarmupCallback(beta, WARMUP_EPOCHS),\n",
    "    \n",
    "    # Reduce learning rate on plateau\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=5e-5,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Early stopping (start after warmup phase)\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        start_from_epoch=WARMUP_EPOCHS // 2,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train\n",
    "print(f\"\\nTraining VAE with latent_dim={LATENT_DIM}, warmup_epochs={WARMUP_EPOCHS}\")\n",
    "print(f\"Total epochs: {EPOCHS}, batch_size: {BATCH_SIZE}, learning_rate: {LEARNING_RATE}\\n\")\n",
    "\n",
    "history = vae.fit(\n",
    "    x_train, x_train,  # Input = output for autoencoders\n",
    "    validation_data=(x_test, x_test),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=callback_list,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Utility: Deterministic Reconstruction (z = μ)\n",
    "# ============================================================================\n",
    "\n",
    "def deterministic_recon(encoder, decoder, x):\n",
    "    \"\"\"\n",
    "    Get deterministic reconstructions using z = mu (no sampling).\n",
    "    \n",
    "    Args:\n",
    "        encoder: Encoder model\n",
    "        decoder: Decoder model\n",
    "        x: Input images, shape (N, 28, 28, 1)\n",
    "    \n",
    "    Returns:\n",
    "        x_recon: Reconstructed images using z = mu\n",
    "        mu: Mean vectors in latent space\n",
    "    \"\"\"\n",
    "    z_mean, z_log_var, z_sample = encoder.predict(x, verbose=0)\n",
    "    x_recon = decoder.predict(z_mean, verbose=0)  # Use mean, not sampled z\n",
    "    return x_recon, z_mean\n",
    "\n",
    "\n",
    "def show_reconstructions(encoder, decoder, x_test, n=10, seed=42):\n",
    "    \"\"\"\n",
    "    Show original images vs deterministic reconstructions.\n",
    "    \n",
    "    Args:\n",
    "        encoder: Encoder model\n",
    "        decoder: Decoder model\n",
    "        x_test: Test images\n",
    "        n: Number of samples to show\n",
    "        seed: Random seed for sample selection\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    indices = rng.choice(len(x_test), size=n, replace=False)\n",
    "    x_subset = x_test[indices]\n",
    "    \n",
    "    x_recon, _ = deterministic_recon(encoder, decoder, x_subset)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, n, figsize=(1.5*n, 3))\n",
    "    for i in range(n):\n",
    "        # Original\n",
    "        axes[0, i].imshow(x_subset[i].squeeze(), cmap='gray', vmin=0, vmax=1)\n",
    "        axes[0, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[0, i].set_title('Original', fontsize=10)\n",
    "        \n",
    "        # Reconstruction\n",
    "        axes[1, i].imshow(x_recon[i].squeeze(), cmap='gray', vmin=0, vmax=1)\n",
    "        axes[1, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[1, i].set_title('Recon (z=μ)', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Show some reconstructions\n",
    "show_reconstructions(encoder, decoder, x_test, n=10, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Plot Training History\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Total loss\n",
    "axes[0, 0].plot(history.history['loss'], label='Train Loss')\n",
    "axes[0, 0].plot(history.history['val_loss'], label='Val Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Total Loss')\n",
    "axes[0, 0].set_title('Total Loss (Recon + β×KL)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Reconstruction loss\n",
    "axes[0, 1].plot(history.history['recon_loss'], label='Train Recon')\n",
    "if 'val_recon_loss' in history.history:\n",
    "    axes[0, 1].plot(history.history['val_recon_loss'], label='Val Recon')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Reconstruction Loss')\n",
    "axes[0, 1].set_title('Reconstruction Loss (MSE)')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# KL loss (unscaled)\n",
    "axes[1, 0].plot(history.history['kl_loss'], label='Train KL')\n",
    "if 'val_kl_loss' in history.history:\n",
    "    axes[1, 0].plot(history.history['val_kl_loss'], label='Val KL')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('KL Divergence')\n",
    "axes[1, 0].set_title('KL Loss (unscaled)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Beta (warmup schedule)\n",
    "axes[1, 1].plot(history.history['kl_beta'], label='β (KL weight)', color='green')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Beta Value')\n",
    "axes[1, 1].set_title('KL Warmup Schedule')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3.5 Latent space visualization and evaluation\n",
    "\n",
    "Now that we have a trained VAE, we can:\n",
    "1. **Visualize the latent space**: Plot 2D scatter of test samples (colored by class)\n",
    "2. **Generate from latent space**: Sample a grid in latent space and decode to images\n",
    "3. **Evaluate reconstruction quality**: Compute MSE and SSIM metrics\n",
    "4. **Assess latent clustering**: Use k-NN accuracy as a proxy for separability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 1. Latent Space Scatter Plot (2D, colored by class)\n",
    "# ============================================================================\n",
    "\n",
    "# Encode test set to latent space\n",
    "z_mean_test, z_log_var_test, z_sample_test = encoder.predict(x_test, verbose=0)\n",
    "\n",
    "# For readability, subsample to ~4000 points\n",
    "n_plot = min(4000, len(x_test))\n",
    "indices = np.random.choice(len(x_test), n_plot, replace=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(\n",
    "    z_mean_test[indices, 0],\n",
    "    z_mean_test[indices, 1],\n",
    "    c=y_test[indices],\n",
    "    cmap='tab10',\n",
    "    alpha=0.6,\n",
    "    s=10\n",
    ")\n",
    "plt.colorbar(scatter, label='Class')\n",
    "plt.xlabel('Latent Dimension 1')\n",
    "plt.ylabel('Latent Dimension 2')\n",
    "plt.title('Latent Space Visualization (Test Set)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Plotted {n_plot} test samples in 2D latent space.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 2. Manifold Grid Visualization\n",
    "# ============================================================================\n",
    "\n",
    "# Sample a regular grid in latent space [-3, 3] x [-3, 3]\n",
    "n_grid = 15\n",
    "grid_x = np.linspace(-3, 3, n_grid)\n",
    "grid_y = np.linspace(-3, 3, n_grid)\n",
    "\n",
    "# Create meshgrid\n",
    "xx, yy = np.meshgrid(grid_x, grid_y)\n",
    "z_grid = np.column_stack([xx.flatten(), yy.flatten()]).astype('float32')\n",
    "\n",
    "# Decode grid points\n",
    "x_decoded = decoder.predict(z_grid, verbose=0)\n",
    "\n",
    "# Plot grid\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "for i in range(n_grid * n_grid):\n",
    "    ax = plt.subplot(n_grid, n_grid, i + 1)\n",
    "    ax.imshow(x_decoded[i].squeeze(), cmap='gray', vmin=0, vmax=1)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Latent Space Manifold: 15×15 Grid in [-3, 3]²', fontsize=16, y=0.995)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "plt.show()\n",
    "\n",
    "print(f\"Generated {n_grid}×{n_grid} images from latent grid.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 3. Quantitative Metrics: MSE, SSIM, k-NN Accuracy\n",
    "# ============================================================================\n",
    "\n",
    "def compute_reconstruction_metrics(encoder, decoder, x_test, y_test, n_samples=1000):\n",
    "    \"\"\"\n",
    "    Compute reconstruction quality metrics.\n",
    "    \n",
    "    Args:\n",
    "        encoder: Encoder model\n",
    "        decoder: Decoder model\n",
    "        x_test: Test images\n",
    "        y_test: Test labels\n",
    "        n_samples: Number of samples to evaluate (for speed)\n",
    "    \n",
    "    Returns:\n",
    "        dict with MSE, SSIM, and k-NN accuracy\n",
    "    \"\"\"\n",
    "    # Sample subset for evaluation\n",
    "    indices = np.random.choice(len(x_test), min(n_samples, len(x_test)), replace=False)\n",
    "    x_subset = x_test[indices]\n",
    "    y_subset = y_test[indices]\n",
    "    \n",
    "    # Get reconstructions (deterministic)\n",
    "    x_recon, z_mean_subset = deterministic_recon(encoder, decoder, x_subset)\n",
    "    \n",
    "    # 1. MSE (per-pixel mean squared error)\n",
    "    mse = np.mean((x_subset - x_recon) ** 2)\n",
    "    \n",
    "    # 2. SSIM (structural similarity index)\n",
    "    # Convert to tensors for tf.image.ssim\n",
    "    x_subset_tf = tf.constant(x_subset)\n",
    "    x_recon_tf = tf.constant(x_recon)\n",
    "    ssim_values = tf.image.ssim(x_subset_tf, x_recon_tf, max_val=1.0)\n",
    "    ssim_mean = float(tf.reduce_mean(ssim_values).numpy())\n",
    "    \n",
    "    # 3. k-NN accuracy (measure of latent space clustering)\n",
    "    # Use entire test set latent representations\n",
    "    z_mean_all, _, _ = encoder.predict(x_test, verbose=0)\n",
    "    \n",
    "    try:\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        \n",
    "        # Split for k-NN evaluation\n",
    "        z_train, z_val, y_train_knn, y_val_knn = train_test_split(\n",
    "            z_mean_all, y_test, test_size=0.3, random_state=42, stratify=y_test\n",
    "        )\n",
    "        \n",
    "        # Train k-NN classifier\n",
    "        knn = KNeighborsClassifier(n_neighbors=5)\n",
    "        knn.fit(z_train, y_train_knn)\n",
    "        knn_accuracy = knn.score(z_val, y_val_knn)\n",
    "    except ImportError:\n",
    "        print(\"Note: scikit-learn not available, skipping k-NN accuracy.\")\n",
    "        knn_accuracy = None\n",
    "    \n",
    "    return {\n",
    "        'mse': mse,\n",
    "        'ssim': ssim_mean,\n",
    "        'knn_accuracy': knn_accuracy\n",
    "    }\n",
    "\n",
    "\n",
    "# Compute metrics\n",
    "print(\"Computing reconstruction metrics...\")\n",
    "metrics = compute_reconstruction_metrics(encoder, decoder, x_test, y_test, n_samples=1000)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RECONSTRUCTION QUALITY METRICS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"MSE (per-pixel):      {metrics['mse']:.6f}\")\n",
    "print(f\"SSIM (avg):           {metrics['ssim']:.4f}\")\n",
    "if metrics['knn_accuracy'] is not None:\n",
    "    print(f\"k-NN Accuracy (k=5):  {metrics['knn_accuracy']:.4f}\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Lower MSE = better pixel-wise reconstruction\")\n",
    "print(\"- Higher SSIM (0-1) = better structural similarity\")\n",
    "print(\"- Higher k-NN accuracy = better latent space clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 4. Final Reconstruction Panel (10 Random Test Samples)\n",
    "# ============================================================================\n",
    "\n",
    "show_reconstructions(encoder, decoder, x_test, n=10, seed=123)\n",
    "print(\"\\n✓ Latent space visualization and evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook implements a complete Variational Autoencoder (VAE) for Fashion-MNIST with:\n",
    "\n",
    "### Key Features:\n",
    "1. **Clean loss functions (4.3.3)**: MSE reconstruction + analytic KL divergence\n",
    "2. **Stable VAE implementation (4.3.4)**: Functional API with add_loss/add_metric, KL warmup, proper callbacks\n",
    "3. **Latent space analysis (4.3.5)**: 2D scatter, manifold grid, reconstruction quality metrics\n",
    "\n",
    "### Training Strategy:\n",
    "- **KL warmup**: β increases linearly from 0→1 over 40 epochs to stabilize training\n",
    "- **ReduceLROnPlateau**: Halves learning rate when validation loss plateaus\n",
    "- **EarlyStopping**: Stops training if no improvement after 10 epochs (starts after epoch 20)\n",
    "\n",
    "### Architecture:\n",
    "- **Latent dimension**: 2 (enables direct 2D visualization)\n",
    "- **Encoder**: 4 Conv2D layers → Dense → z_mean, z_log_var\n",
    "- **Decoder**: Dense → 5 Conv2DTranspose layers → sigmoid output\n",
    "\n",
    "### Notes:\n",
    "- All loss functions return scalars as required\n",
    "- Metrics (recon_loss, kl_loss, kl_scaled, kl_beta) are visible during training\n",
    "- No tensor closure issues (uses functional API properly)\n",
    "- Notebook runs from start to finish after kernel restart"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}